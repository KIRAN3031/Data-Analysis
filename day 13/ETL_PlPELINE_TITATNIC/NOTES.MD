# ETL PIPELINE

    An ETL pipeline is used to move data from different source systems into a single, clean, organized place (like a data warehouse) so it can be used for reporting, dashboards, and analytics effectively.

# ETL stands for Extract Transform Load Pipeline
    Extract: Read or pull raw data from various sources such as transactional databases, CSV files, APIs, logs, etc.
    Transform: Clean, validate, standardize, join, aggregate, and apply business rules so that data becomes consistent and meaningful.
    Load: Write the transformed data into a target system like a data warehouse, data mart, or analytics database, usually on a schedule (e.g., hourly, daily).

# Main uses
    1. Data Integration
    2. Data cleaning and standardization
    3. Analytics and BI enabelment
    4. Governance and compliance
    5. Performance and cost optimization