# Customer Churn Prediction Analytics for a Telecom Company
    A telecom operator named TeleConnect is facing customer churn (customers leaving the service).
    Their data team wants to analyze customer behavior and produce a high-quality cleaned dataset for future ML modeling.
    You are assigned to build a full ETL pipeline:
    Extract ‚Üí Transform ‚Üí Load ‚Üí Validate ‚Üí Generate Analytics Summary.

# 1.EXTRACT (extract.py)

    Write a script that:
        Creates folder structure:
        data/raw
        data/staged
        data/processed
        import opendatasets as od
        load the dataset
        data/raw/churn_raw.csv
        Save raw CSV as:data/raw/churn_raw.csv

# 2.TRANSFORM (transform.py)
    must perform advanced transformations, not just cleaning.
    ‚úî Cleaning Tasks
    Convert "TotalCharges" to numeric (dataset has spaces ‚Üí become NaN).
    Fill missing numeric values using:
    Median for tenure, MonthlyCharges, TotalCharges.
    Replace missing categorical values with "Unknown".
    ‚úî Feature Engineering
    Create the following new columns:
    1. tenure_group
    Based on tenure months:
    0‚Äì12   ‚Üí "New"
    13‚Äì36  ‚Üí "Regular"
    37‚Äì60  ‚Üí "Loyal"
    60+    ‚Üí "Champion"
    2. monthly_charge_segment
    MonthlyCharges < 30  ‚Üí "Low"
    30‚Äì70              ‚Üí "Medium"
    > 70                 ‚Üí "High"
    3. has_internet_service
    Convert InternetService column:
    "DSL" / "Fiber optic" ‚Üí 1
    "No" ‚Üí 0
    4. is_multi_line_user
    1 if MultipleLines == "Yes"
    0 otherwise
    5. contract_type_code
    Map:
    Month-to-month ‚Üí 0
    One year      ‚Üí 1
    Two year      ‚Üí 2
    ‚úî Drop unnecessary fields
    Remove:
    customerID, gender
    ‚úî Save output to:
    data/staged/churn_transformed.csv

# 3Ô∏è.LOAD TO SUPABASE (load.py)
    Create a table:
    id BIGSERIAL PRIMARY KEY,
    tenure INTEGER,
    MonthlyCharges FLOAT,
    TotalCharges FLOAT,
    Churn TEXT,
    InternetService TEXT,
    Contract TEXT,
    PaymentMethod TEXT,
    tenure_group TEXT,
    monthly_charge_segment TEXT,
    has_internet_service INTEGER,
    is_multi_line_user INTEGER,
    contract_type_code INTEGER
    Load Data
    Batch size = 200 records at a time
    Convert NaN ‚Üí None
    Insert with error handling + retry logic


# 4.VALIDATION SCRIPT (validate.py)
    After load, write a script that checks:
    No missing values in:
    tenure, MonthlyCharges, TotalCharges
    Unique count of rows = original dataset
    Row count matches Supabase table
    All segments (tenure_group, monthly_charge_segment) exist
    Contract codes are only {0,1,2}
    Print a validation summary.

# 5.ANALYSIS REPORT (etl_analysis.py)
    Read table from Supabase and generate:
    üìä Metrics
    Churn percentage
    Average monthly charges per contract
    Count of new, regular, loyal, champion customers
    Internet service distribution
    Pivot table: Churn vs Tenure Group
    Optional visualizations:
    Churn rate by Monthly Charge Segment
    Histogram of TotalCharges
    Bar plot of Contract types
    Save output CSV into:
    data/processed/analysis_summary.csv